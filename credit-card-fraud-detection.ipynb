{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# IMPORT PACKAGES","metadata":{"papermill":{"duration":0.024579,"end_time":"2021-01-30T22:43:10.86624","exception":false,"start_time":"2021-01-30T22:43:10.841661","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Sun Aug  2 02:56:46 2020\n@author: Ouedraogo Abdoul-Fatao\n\"\"\"\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport keras\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Input, Dense, Lambda\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras import regularizers\nimport scipy.io as sio\nfrom sklearn import preprocessing\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (accuracy_score, auc, recall_score,f1_score, \nclassification_report, precision_recall_curve,recall_score,\nprecision_recall_fscore_support, roc_curve, confusion_matrix, precision_score)\n\ntf.compat.v1.disable_eager_execution()","metadata":{"execution":{"iopub.execute_input":"2021-01-30T22:43:10.923049Z","iopub.status.busy":"2021-01-30T22:43:10.922094Z","iopub.status.idle":"2021-01-30T22:43:17.437199Z","shell.execute_reply":"2021-01-30T22:43:17.437726Z"},"papermill":{"duration":6.5483,"end_time":"2021-01-30T22:43:17.437934","exception":false,"start_time":"2021-01-30T22:43:10.889634","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# IMPORT DATASET","metadata":{"papermill":{"duration":0.023233,"end_time":"2021-01-30T22:43:17.484862","exception":false,"start_time":"2021-01-30T22:43:17.461629","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Import dataset from repertory\ndata =pd.read_csv(\"../input/credit-card-detection/creditcard.csv\")\ndata.head(10)","metadata":{"execution":{"iopub.execute_input":"2021-01-30T22:43:17.535195Z","iopub.status.busy":"2021-01-30T22:43:17.534261Z","iopub.status.idle":"2021-01-30T22:43:21.550381Z","shell.execute_reply":"2021-01-30T22:43:21.550835Z"},"papermill":{"duration":4.04269,"end_time":"2021-01-30T22:43:21.55096","exception":false,"start_time":"2021-01-30T22:43:17.50827","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DATA ANALYSIS","metadata":{"papermill":{"duration":0.028727,"end_time":"2021-01-30T22:43:21.604355","exception":false,"start_time":"2021-01-30T22:43:21.575628","status":"completed"},"tags":[]}},{"cell_type":"code","source":"print('Shape:\\n', data.shape)   # Dimension of the data\nprint('Data type', data.dtypes.value_counts())\nprint(' columns:\\n', data.columns) #Number of columns\ncount_class= pd.value_counts(data['Class'], sort = True)\nprint('Number of classes:\\n',count_class)\nprint('Information on the dataset:\\n', data.info())\nprint('Dataset description:\\n', data.describe())\nprint('Check Missing values', data.isnull().sum())\nprint('Check duplicate values',data.duplicated() )","metadata":{"execution":{"iopub.execute_input":"2021-01-30T22:43:21.677111Z","iopub.status.busy":"2021-01-30T22:43:21.676211Z","iopub.status.idle":"2021-01-30T22:43:22.686573Z","shell.execute_reply":"2021-01-30T22:43:22.687074Z"},"papermill":{"duration":1.053492,"end_time":"2021-01-30T22:43:22.687213","exception":false,"start_time":"2021-01-30T22:43:21.633721","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# VISUALIZATION","metadata":{"papermill":{"duration":0.026301,"end_time":"2021-01-30T22:43:22.739338","exception":false,"start_time":"2021-01-30T22:43:22.713037","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Distribution Analysis:\nprint((\"Distribution of fraudulent points: {:.2f}%\".format(len(data[data['Class']==1])/len(data)*50)))\nsns.countplot(data['Class'])\nplt.title('Class Distribution')\nplt.xticks(range(2),['Normal','Fraud'])\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2021-01-30T22:43:22.797658Z","iopub.status.busy":"2021-01-30T22:43:22.797011Z","iopub.status.idle":"2021-01-30T22:43:22.983492Z","shell.execute_reply":"2021-01-30T22:43:22.98291Z"},"papermill":{"duration":0.218553,"end_time":"2021-01-30T22:43:22.9836","exception":false,"start_time":"2021-01-30T22:43:22.765047","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation matrix \ncorrmat = data.corr() \nfig = plt.figure(figsize = (8, 6)) \nsns.heatmap(corrmat, vmax = .8, square = True) \nplt.show()","metadata":{"execution":{"iopub.execute_input":"2021-01-30T22:43:23.043905Z","iopub.status.busy":"2021-01-30T22:43:23.043248Z","iopub.status.idle":"2021-01-30T22:43:24.166927Z","shell.execute_reply":"2021-01-30T22:43:24.166297Z"},"papermill":{"duration":1.156487,"end_time":"2021-01-30T22:43:24.167061","exception":false,"start_time":"2021-01-30T22:43:23.010574","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Amount per transaction by class\nf, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize = (10,10) )\nf.suptitle('Amount per transaction by class')\n\nbins = 10\nax1.hist(Fraud.Amount, bins = bins)\nax1.set_title('Fraud')\nax2.hist(Normal.Amount, bins = bins)\nax2.set_title('Normal')\n\nax1.grid()\nax2.grid()\nplt.xlabel('Amount ($)')\nplt.ylabel('Number of Transactions')\nplt.xlim((0, 20000))\nplt.yscale('log')\nplt.show();","metadata":{"execution":{"iopub.execute_input":"2021-01-30T22:43:24.237069Z","iopub.status.busy":"2021-01-30T22:43:24.231956Z","iopub.status.idle":"2021-01-30T22:43:24.881432Z","shell.execute_reply":"2021-01-30T22:43:24.880778Z"},"papermill":{"duration":0.686476,"end_time":"2021-01-30T22:43:24.881536","exception":false,"start_time":"2021-01-30T22:43:24.19506","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Time of transaction vs Amount by class'\nf, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(10,10))\nf.suptitle('Time of transaction vs Amount by class')\n\nax1.scatter(Fraud.Time, Fraud.Amount, marker='.')\nax1.set_title('Fraud')\nax1.grid()\nax2.scatter(Normal.Time, Normal.Amount, marker='.')\nax2.set_title('Normal')\nax2.grid()\nplt.xlabel('Time (in Seconds)')\nplt.ylabel('Amount')\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2021-01-30T22:43:24.954364Z","iopub.status.busy":"2021-01-30T22:43:24.951775Z","iopub.status.idle":"2021-01-30T22:43:25.298438Z","shell.execute_reply":"2021-01-30T22:43:25.297838Z"},"papermill":{"duration":0.388294,"end_time":"2021-01-30T22:43:25.298573","exception":false,"start_time":"2021-01-30T22:43:24.910279","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DATA PROCESSING","metadata":{"papermill":{"duration":0.028741,"end_time":"2021-01-30T22:43:25.357631","exception":false,"start_time":"2021-01-30T22:43:25.32889","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Delete  Time \ndf =data.drop(['Time'], axis=1)\n# Separate Normal  and fraud data\nNormal= df[df.Class==0]\nFraud = df[df.Class==1]","metadata":{"execution":{"iopub.execute_input":"2021-01-30T22:43:25.445733Z","iopub.status.busy":"2021-01-30T22:43:25.445031Z","iopub.status.idle":"2021-01-30T22:43:25.487009Z","shell.execute_reply":"2021-01-30T22:43:25.486451Z"},"papermill":{"duration":0.100834,"end_time":"2021-01-30T22:43:25.487123","exception":false,"start_time":"2021-01-30T22:43:25.386289","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Splitting our Training set\nX_train, X_test_normal = train_test_split(Normal, test_size= 0.2, random_state=27)\nY_train =X_train['Class']\nX_train = X_train.drop(['Class'], axis=1)\nX_val = X_test_normal.drop(['Class'], axis=1)","metadata":{"execution":{"iopub.execute_input":"2021-01-30T22:43:25.560891Z","iopub.status.busy":"2021-01-30T22:43:25.554322Z","iopub.status.idle":"2021-01-30T22:43:25.666567Z","shell.execute_reply":"2021-01-30T22:43:25.665996Z"},"papermill":{"duration":0.148706,"end_time":"2021-01-30T22:43:25.666684","exception":false,"start_time":"2021-01-30T22:43:25.517978","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Concatenate fraud to X_test_normal\nX_test = pd.concat([Fraud, X_test_normal], ignore_index=True)\nY_test = X_test['Class']\nX_test = X_test.drop(['Class'], axis=1)\n\n# Normalize colomn Amount\nscaler = StandardScaler().fit(X_train.Amount.values.reshape(-1,1))\nX_train['Amount'] = scaler.transform(X_train.Amount.values.reshape(-1,1))\nX_test['Amount'] = scaler.transform(X_test.Amount.values.reshape(-1,1))\nX_val['Amount'] = scaler.transform(X_val.Amount.values.reshape(-1,1))\n\n#Transform data to array     \nX_train =X_train.values\nX_test = X_test.values\nX_val = X_val.values","metadata":{"execution":{"iopub.execute_input":"2021-01-30T22:43:25.735779Z","iopub.status.busy":"2021-01-30T22:43:25.735151Z","iopub.status.idle":"2021-01-30T22:43:25.758062Z","shell.execute_reply":"2021-01-30T22:43:25.757494Z"},"papermill":{"duration":0.062027,"end_time":"2021-01-30T22:43:25.758174","exception":false,"start_time":"2021-01-30T22:43:25.696147","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# IMPLEMENTATION OF VARIATIONAL AUTOENCODER","metadata":{"papermill":{"duration":0.03013,"end_time":"2021-01-30T22:43:25.819105","exception":false,"start_time":"2021-01-30T22:43:25.788975","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Setup the network parameters:\noriginal_dim = X_train.shape[1]\ninput_shape = (original_dim, )\nencoding_dim = 25\nhidden_dim = 10\nbatch_size = 16\nlatent_dim = 10\nepochs =100\n\n# build encoder model : P(z | x )\ninputs =  Input(shape=(original_dim, ))\nx = Dense(encoding_dim, activation='relu')(inputs)\nx = Dense(hidden_dim, activation='relu')(x)\n#Q_x(z) ={g(x), h(x)}\nmean = Dense(latent_dim,name='mean')(x)          #g(x)\nlog_var = Dense(latent_dim, name='log_var')(x)   #h(x)\n\n# Définition d'une fonction d'échantillonnage\ndef sampling(args):\n    mean, log_var = args\n    batch = K.shape(mean)[0]  # le nombre d'observation\n    dim = K.int_shape(mean)[1]  #  dimension \n    epsilon = K.random_normal(shape=(batch, dim))\n    return mean + K.exp(0.5 * log_var) * epsilon\n\n#Utilisation d'une couche Keras Lambda pour inclure la fonction d'échantillonnage en tant que couche de sortie\nz = Lambda(sampling)([mean, log_var])\n\n#Instantiate encoder model\nencoder = Model(inputs, mean)\nprint('Encoder summary\\n')\nencoder.summary()\n#SVG(model_to_dot(encoder,show_shapes=True).create(prog='dot', format='svg'))\n\n# Build the decoder model: P(x | z)\nlaten_inputs = Input(shape=(latent_dim,), name='z_sampling')\nx_decoded = Dense(hidden_dim, activation='relu')(laten_inputs)\nx_decoded = Dense(encoding_dim, activation='relu')(x_decoded)\nx_decoded = Dense(original_dim, activation='linear')(x_decoded)\n\n# instantiate decoder model\ndecoder = Model(laten_inputs, x_decoded, name='decoder')\nprint('Decoder summary\\n')\ndecoder.summary()\n#SVG(model_to_dot(decoder,show_shapes=True).create(prog='dot', format='svg'))\n\n# Instantiate the VAE model:\noutputs = decoder(encoder(inputs))\nvae = Model(inputs, outputs, name='vae_mlp')\nprint('Variational autoencoder summary\\n')\nvae.summary()\n#SVG(model_to_dot(vae,show_shapes=True).create(prog='dot', format='svg'))","metadata":{"execution":{"iopub.execute_input":"2021-01-30T22:43:25.896126Z","iopub.status.busy":"2021-01-30T22:43:25.895369Z","iopub.status.idle":"2021-01-30T22:43:26.066433Z","shell.execute_reply":"2021-01-30T22:43:26.065242Z"},"papermill":{"duration":0.217465,"end_time":"2021-01-30T22:43:26.066555","exception":false,"start_time":"2021-01-30T22:43:25.84909","status":"completed"},"tags":[],"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recon_loss(x, x_decoded):\n    return K.mean(K.square(x_decoded - x), axis= 1)\n\n# kl _loss\ndef kl_loss(x, x_decoded):    \n    return -0.5 * K.mean(1 + log_var - K.square(mean) - K.exp(log_var), axis = -1)\n   \n#Vae_loss = recon_loss+kl_loss\ndef vae_loss(x, x_decoded):\n    \"\"\" Calculate loss = reconstruction loss + KL loss for each data in minibatch \"\"\"\n    \n    recon_loss= K.mean(K.square(x_decoded - x), axis= 1)\n    kl_loss = -0.5 * K.mean(1 + log_var - K.square(mean) - K.exp(log_var), axis = -1)\n   \n    return recon_loss + kl_loss\n\n# Compile model\nLearning_rate= 1e-7\noptimizer= keras.optimizers.Adam(learning_rate=Learning_rate)\nvae.compile(optimizer='adam', loss= vae_loss, metrics=['accuracy'])\n\ncp = ModelCheckpoint(filepath=\"/content/drive/My Drive/FraudDetection/vae.h5\",\n                               save_best_only=True,\n                               verbose=0)\n#Train the model:\nhistory = vae.fit(X_train, X_train,\n        shuffle=True,\n        epochs=epochs,\n        batch_size=batch_size,       \n        validation_data=(X_val, X_val))","metadata":{"execution":{"iopub.execute_input":"2021-01-30T22:43:26.14506Z","iopub.status.busy":"2021-01-30T22:43:26.144003Z","iopub.status.idle":"2021-01-30T23:20:29.79608Z","shell.execute_reply":"2021-01-30T23:20:29.797294Z"},"papermill":{"duration":2223.699175,"end_time":"2021-01-30T23:20:29.797553","exception":false,"start_time":"2021-01-30T22:43:26.098378","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualization of loss fonction\nplt.plot(history.history['loss'], 'b')\nplt.plot( history.history['val_loss'], 'r')\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.grid()\nplt.legend(['Train_loss', 'Val_loss'], loc='upper right');\nplt.show()\n\n# plot accuracy during training\nplt.title('Accuracy')\nplt.plot(history.history['accuracy'], label='Train_accuracy')\nplt.plot(history.history['val_accuracy'], label='Val_accuracy')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2021-01-30T23:20:54.923927Z","iopub.status.busy":"2021-01-30T23:20:54.92297Z","iopub.status.idle":"2021-01-30T23:20:55.429052Z","shell.execute_reply":"2021-01-30T23:20:55.428416Z"},"papermill":{"duration":13.07081,"end_time":"2021-01-30T23:20:55.429174","exception":false,"start_time":"2021-01-30T23:20:42.358364","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediction X_test\npredictions = vae.predict(X_test)","metadata":{"execution":{"iopub.execute_input":"2021-01-30T23:21:20.848315Z","iopub.status.busy":"2021-01-30T23:21:20.847531Z","iopub.status.idle":"2021-01-30T23:21:22.049031Z","shell.execute_reply":"2021-01-30T23:21:22.048484Z"},"papermill":{"duration":13.918789,"end_time":"2021-01-30T23:21:22.04914","exception":false,"start_time":"2021-01-30T23:21:08.130351","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calculating the mean squared error reconstruction loss per row in the numpy array\nmse = np.mean((predictions - X_test)**2,  axis=1)\n\n# showing the reconstruction losses for a subsample of transactions\nsample_size = 30\n\nprint(f'Mean Squared Error reconstruction losses for {sample_size} normal transactions:\\n')\nprint(mse[np.where(Y_test==0)][:sample_size])\n\nprint(f'\\nMean Squared Error reconstruction losses for {sample_size} fraudulent transactions:\\n')\nprint(mse[np.where(Y_test==1)][:sample_size])\n\nerror_df = pd.DataFrame({'reconstruction_error': mse, 'true_class':Y_test})","metadata":{"execution":{"iopub.execute_input":"2021-01-30T23:21:47.559818Z","iopub.status.busy":"2021-01-30T23:21:47.559153Z","iopub.status.idle":"2021-01-30T23:21:47.589066Z","shell.execute_reply":"2021-01-30T23:21:47.589933Z"},"papermill":{"duration":12.805976,"end_time":"2021-01-30T23:21:47.59021","exception":false,"start_time":"2021-01-30T23:21:34.784234","status":"completed"},"tags":[],"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot Density distribution between normal data and fraud data\nmseNormal= mse[np.where(Y_test==0)]\nmseFraud= mse[np.where(Y_test==1)]\nsns.kdeplot(mseNormal, shade= True, color='b',bw=0.1)\nsns.kdeplot(mseFraud, shade= True, color='r',bw=0.1)","metadata":{"execution":{"iopub.execute_input":"2021-01-30T23:22:12.855572Z","iopub.status.busy":"2021-01-30T23:22:12.854898Z","iopub.status.idle":"2021-01-30T23:22:13.002604Z","shell.execute_reply":"2021-01-30T23:22:13.001982Z"},"papermill":{"duration":12.693481,"end_time":"2021-01-30T23:22:13.002714","exception":false,"start_time":"2021-01-30T23:22:00.309233","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CALCULATE RESIDUALS OF X_TRAIN AND X_TEST**","metadata":{"papermill":{"duration":12.597416,"end_time":"2021-01-30T23:22:38.249001","exception":false,"start_time":"2021-01-30T23:22:25.651585","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Residu de x_train\nr_xtrain = X_train - vae.predict(X_train)\nprint(\"Residuals of Xtrain\\n\",r_xtrain)\nprint('\\n')\nr_xtest  = X_test - vae.predict(X_test)\nprint(\"Residuals of Xtest\\n\",r_xtest)","metadata":{"execution":{"iopub.execute_input":"2021-01-30T23:23:03.389592Z","iopub.status.busy":"2021-01-30T23:23:03.388573Z","iopub.status.idle":"2021-01-30T23:23:09.25474Z","shell.execute_reply":"2021-01-30T23:23:09.255559Z"},"papermill":{"duration":18.455852,"end_time":"2021-01-30T23:23:09.255717","exception":false,"start_time":"2021-01-30T23:22:50.799865","status":"completed"},"tags":[],"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# IMPLEMENTATION OF SVDD MODEL","metadata":{"papermill":{"duration":12.651514,"end_time":"2021-01-30T23:23:34.503894","exception":false,"start_time":"2021-01-30T23:23:21.85238","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!pip install cvxopt","metadata":{"execution":{"iopub.execute_input":"2021-01-30T23:23:59.567085Z","iopub.status.busy":"2021-01-30T23:23:59.566096Z","iopub.status.idle":"2021-01-30T23:24:11.419193Z","shell.execute_reply":"2021-01-30T23:24:11.418458Z"},"papermill":{"duration":24.349707,"end_time":"2021-01-30T23:24:11.419309","exception":false,"start_time":"2021-01-30T23:23:47.069602","status":"completed"},"tags":[],"collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\nimport numpy as np\nfrom cvxopt import matrix, solvers\nimport sklearn.metrics.pairwise as smp\nimport time\n\nclass SVDD():\n    \n    def __init__(self, parameters):\n        \n        \"\"\" \n        DESCRIPTION\n        \n        --------------------------------------------------        \n        INPUT\n          parameters   \n\n             \"positive penalty\": positive penalty factor\n             \"negative penalty\": negative penalty factor\n             \"kernel\"          : kernel function         \n             \"option\"          : some options \n             \n        \n        \"\"\"                \n        self.parameters = parameters\n\n\n\n    def train(self, data, label):\n        \n        \"\"\" \n        DESCRIPTION\n        \n        Train SVDD model\n        \n        -------------------------------------------------- \n        Reference\n        Tax, David MJ, and Robert PW Duin.\n        \"Support vector data description.\" \n        Machine learning 54.1 (2004): 45-66.\n        \n        -------------------------------------------------- \n        model = train(data, label)\n        \n        --------------------------------------------------        \n        INPUT\n        data        Training data (n*d) \n                        n: number of samples\n                        d: number of features\n        label       Training label (n*1)\n                        positive: 1\n                        negative: -1\n                        \n        OUTPUT\n        model       SVDD hypersphere\n        --------------------------------------------------\n        \n        \"\"\"\n        start_time = time.time()\n        \n        label = np.array(label, dtype = 'int')      \n        if np.abs(np.sum(label)) == data.shape[0]:\n            self.labeltype = 'single'\n        else:\n            self.labeltype = 'hybrid'\n        \n        # index of positive and negative samples\n        pIndex = label[:,0] == 1\n        nIndex = label[:,0] == -1\n        \n        # threshold for support vectors\n        threshold = 1e-7\n        \n        # compute the kernel matrix\n        K = self.getMatrix(data, data)\n\n        # solve the Lagrange dual problem\n        alf, obj, iteration = self.quadprog(K, label)\n        \n        # find the index of support vectors\n        sv_index = np.where(alf > threshold)[0][:]\n\n        # support vectors and alf\n        sv_value = data[sv_index, :]\n        sv_alf = alf[sv_index]\n        \n        # compute the center of initial feature space\n        center = np.dot(alf.T, data)\n        \n        ''''\n        compute the radius: eq(15)\n        \n        The distance from any support vector to the center of \n        the sphere is the hypersphere radius. \n        Here take the 1st support vector as an example.\n        \n        '''\n        # the 1st term in eq(15)\n        used = 0\n        term_1 = K[sv_index[used], sv_index[used]]\n        \n        # the 2nd term in eq(15)\n        term_2 = -2*np.dot(K[sv_index[used], :], alf)\n        \n        # the 3rd term in eq(15)\n        term_3 = np.dot(np.dot(alf.T, K), alf)\n\n        # R\n        radius = np.sqrt(term_1+term_2+term_3)\n        \n        end_time = time.time()\n        timecost = end_time - start_time\n        \n        # numbers of positive and negative samples\n        pData = np.sum(pIndex)/data.shape[0]\n        nData = np.sum(nIndex)/data.shape[0]\n        \n        # number of support vectors\n        nSVs = sv_index.shape[0]\n        \n        # ratio of  support vectors\n        rSVs = nSVs/data.shape[0]\n        \n        # store the results\n        self.model = {\"data\"      : data        ,\n                      \"sv_alf\"    : sv_alf      ,\n                      \"radius\"    : radius      ,\n                      \"sv_value\"  : sv_value    ,\n                      \"sv_index\"  : sv_index    ,\n                      \"nSVs\"      : nSVs        ,\n                      \"center\"    : center      ,\n                      \"term_3\"    : term_3      ,\n                      \"alf\"       : alf         ,  \n                      \"K\"         : K           ,\n                      \"pIndex\"    : pIndex      ,\n                      \"nIndex\"    : nIndex      ,\n                      \"obj\"       : obj         ,\n                      \"iteration\" : iteration   ,\n                      \"timecost\"  : timecost    ,\n                      \"pData\"     : pData       ,\n                      \"nData\"     : nData       ,\n                      \"rSVs\"      : rSVs        ,\n                      }\n        \n        # compute the training accuracy\n        display_ = self.parameters[\"option\"][\"display\"]\n        self.parameters[\"option\"][\"display\"] = 'off'\n        _, accuracy = self.test(data, label)\n        self.parameters[\"option\"][\"display\"] = display_      \n        self.model[\"accuracy\"] = accuracy[0]\n        \n        # display training results       \n        if self.parameters[\"option\"][\"display\"] == 'on':\n            print('\\n')\n            print('*** SVDD model training finished ***\\n')\n            print('iter             = %d'       % self.model[\"iteration\"])\n            print('time cost        = %.4f s'   % self.model[\"timecost\"])\n            print('obj              = %.4f'     % self.model[\"obj\"])\n            print('pData            = %.4f %%'  % (100*self.model[\"pData\"]))\n            print('nData            = %.4f %%'  % (100*self.model[\"nData\"]))\n            print('nSVs             = %d'       % self.model[\"nSVs\"])\n            print('radio of nSVs    = %.4f %%'  % (100*self.model[\"rSVs\"]))\n            print('accuracy         = %.4f %%'  % (100*self.model[\"accuracy\"]))\n            print('\\n')\n  \n    def test(self, data, label):\n    \n        \"\"\" \n        DESCRIPTION\n        \n        Test the testing data using the SVDD model\n    \n        distance = test(model, Y)\n        \n        --------------------------------------------------        \n        INPUT\n        data        Test data (n*d) \n                        n: number of samples\n                        d: number of features\n        label       Test label (n*1)\n                        positive: 1\n                        negative: -1\n            \n        OUTPUT\n        distance    Distance between the test data and hypersphere\n        --------------------------------------------------\n        \n        \"\"\"    \n        \n        start_time = time.time()\n        n = data.shape[0]\n        \n        # compute the kernel matrix\n        K = self.getMatrix(data, self.model[\"data\"])\n        \n        # the 1st term\n        term_1 = self.getMatrix(data, data)\n        \n        # the 2nd term\n        tmp_1 = -2*np.dot(K, self.model[\"alf\"])\n        term_2 = np.tile(tmp_1, (1, n))\n        \n        # the 3rd term\n        term_3 =  self.model[\"term_3\"]\n        \n        # distance\n        distance = np.sqrt(np.diagonal(term_1+term_2+term_3))\n        \n        # predicted label\n        predictedlabel = np.mat(np.ones(n)).T\n        fault_index = np.where(distance > self.model[\"radius\"])[1][:]\n        predictedlabel[fault_index] = -1\n            \n        # compute prediction accuracy\n        accuracy = np.sum(predictedlabel == label)/n\n        \n        #compute acc\n        \n        \n        accuracy = accuracy_score(predictedlabel,label)\n        recall = recall_score(predictedlabel,label)\n        precision = precision_score(predictedlabel,label)\n        f1 = f1_score(predictedlabel,label)\n        \n      \n        end_time = time.time()\n        timecost = end_time - start_time\n        if self.parameters[\"option\"][\"display\"] == 'on':\n        # display test results\n            print('\\n')\n            print('*** SVDD model test finished ***\\n')\n            print('time cost        = %.4f s'   % timecost)\n            print('accuracy         = %.4f %%'  % (100*accuracy))\n            print('recall         = %.4f %%'  % (100*recall))\n            print('precision         = %.4f %%'  % (100*precision))\n            print('f1         = %.4f %%'  % (100*f1))\n            print('\\n')\n        \n        \n        return distance, [accuracy,recall,f1,precision]\n\n    def quadprog(self, K, label):\n    \n        \"\"\" \n        DESCRIPTION\n        \n        Solve the Lagrange dual problem\n        \n        quadprog(self, K, label)\n        \n        --------------------------------------------------\n        INPUT\n        K         Kernel matrix\n        label     training label\n        \n                        \n        OUTPUT\n        alf       Lagrange multipliers\n        \n        --------------------------------------------------\n        \n        minimize    (1/2)*x'*P*x + q'*x\n        subject to  G*x <= h\n                    A*x = b                    \n        --------------------------------------------------\n        \n        \"\"\" \n        solvers.options['show_progress'] = False\n        \n        label = np.mat(label)\n        K = np.multiply(label*label.T, K)\n        \n        # P\n        n = K.shape[0]\n        P = K+K.T\n        \n        # q\n        q = -np.multiply(label, np.mat(np.diagonal(K)).T)\n\n        # G\n        G1 = -np.eye(n)\n        G2 = np.eye(n)\n        G = np.append(G1, G2, axis=0)\n        \n        # h\n        h1 = np.mat(np.zeros(n)).T # lb\n        h2 = np.mat(np.ones(n)).T\n        if self.labeltype == 'single':\n            h2[label == 1] = self.parameters[\"positive penalty\"]\n        \n        if self.labeltype == 'hybrid':\n            h2[label == 1] = self.parameters[\"positive penalty\"]\n            h2[label == -1] = self.parameters[\"negative penalty\"]\n\n            \n        h = np.append(h1, h2, axis=0)\n        \n        # A, b\n        A = np.mat(np.ones(n))\n        b = 1.\n        \n        #\n        P = matrix(P)\n        q = matrix(q)\n        G = matrix(G)\n        h = matrix(h)\n        A = matrix(A)\n        b = matrix(b)\n        \n        #\n        sol =solvers.qp(P, q, G, h, A, b)\n        alf = np.array(sol['x'])\n        obj = np.array(sol['dual objective'])\n        iteration = np.array(sol['iterations'])\n\n        return alf, obj, iteration\n\n    def getMatrix(self, X, Y):\n    \n        \"\"\" \n        DESCRIPTION\n        \n        Compute kernel matrix \n        \n        K = getMatrix(X, Y)\n        \n        -------------------------------------------------- \n        INPUT\n        X         data (n*d)\n        Y         data (m*d)\n\n        OUTPUT\n        K         kernel matrix \n        -------------------------------------------------- \n                        \n                            \n        type   -  \n        \n        linear :  k(x,y) = x'*y+c\n        poly   :  k(x,y) = (x'*y+c)^d\n        gauss  :  k(x,y) = exp(-s*||x-y||^2)\n        tanh   :  k(x,y) = tanh(g*x'*y+c)\n        lapl   :  k(x,y) = exp(-s*||x-y||)\n           \n        degree -  d\n        offset -  c\n        width  -  s\n        gamma  -  g\n        \n        --------------------------------------------------      \n        ker    - \n        \n        ker = {\"type\": 'gauss', \"width\": s}\n        ker = {\"type\": 'linear', \"offset\": c}\n        ker = {\"type\": 'ploy', \"degree\": d, \"offset\": c}\n        ker = {\"type\": 'tanh', \"gamma\": g, \"offset\": c}\n        ker = {\"type\": 'lapl', \"width\": s}\n    \n        \"\"\"\n        def gaussFunc():\n            \n            if self.parameters[\"kernel\"].__contains__(\"width\"):\n                s =  self.parameters[\"kernel\"][\"width\"]\n            else:\n                s = 2\n            K = smp.rbf_kernel(X, Y, gamma=s)\n\n                \n            return K\n            \n        def linearFunc():\n            \n            if self.parameters[\"kernel\"].__contains__(\"offset\"):\n                c =  self.parameters[\"kernel\"][\"offset\"]\n            else:\n                c = 0\n\n            K = smp.linear_kernel(X, Y)+c\n            \n            return K\n        \n        def ployFunc():\n            if self.parameters[\"kernel\"].__contains__(\"degree\"):\n                d =  self.parameters[\"kernel\"][\"degree\"]\n            else:\n                d = 2\n                \n            if self.parameters[\"kernel\"].__contains__(\"offset\"):\n                c =  self.parameters[\"kernel\"][\"offset\"]\n            else:\n                c = 0\n                \n            K = smp.polynomial_kernel(X, Y, degree=d, gamma=None, coef0=c)\n            \n            return K\n             \n        def laplFunc():\n            \n            if self.parameters[\"kernel\"].__contains__(\"width\"):\n                s =  self.parameters[\"kernel\"][\"width\"]\n            else:\n                s = 2\n            K = smp.laplacian_kernel(X, Y, gamma=s)\n\n            return K\n    \n        def tanhFunc():\n            if self.parameters[\"kernel\"].__contains__(\"gamma\"):\n                g =  self.parameters[\"kernel\"][\"gamma\"]\n            else:\n                g = 0.01\n                \n            if self.parameters[\"kernel\"].__contains__(\"offset\"):\n                c =  self.parameters[\"kernel\"][\"offset\"]\n            else:\n                c = 1\n            \n            K = smp.sigmoid_kernel(X, Y, gamma=g, coef0=c)\n\n            return K\n\n        kernelType = self.parameters[\"kernel\"][\"type\"]\n        switcher = {    \n                        \"gauss\"   : gaussFunc  ,        \n                        \"linear\"  : linearFunc ,\n                        \"ploy\"    : ployFunc   ,\n                        \"lapl\"    : laplFunc   ,\n                        \"tanh\"    : tanhFunc   ,\n                     }\n        \n        return switcher[kernelType]()","metadata":{"execution":{"iopub.execute_input":"2021-01-30T23:24:36.743979Z","iopub.status.busy":"2021-01-30T23:24:36.720926Z","iopub.status.idle":"2021-01-30T23:24:36.803088Z","shell.execute_reply":"2021-01-30T23:24:36.80395Z"},"papermill":{"duration":12.779341,"end_time":"2021-01-30T23:24:36.804186","exception":false,"start_time":"2021-01-30T23:24:24.024845","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import auc\nfrom mpl_toolkits.mplot3d import Axes3D\nimport time\n\nclass Visualization():\n    \n    def testResult(svdd, distance):\n    \n        \"\"\" \n        DESCRIPTION\n        \n        Plot the test results\n        \n        testResult(model, distance)\n        \n        --------------------------------------------------------------- \n        \n        INPUT\n        svdd             SVDD hypersphere\n        distance         distance from test data to SVDD hypersphere \n        \n        --------------------------------------------------------------- \n        \n        \"\"\"\n        plt.rcParams['font.size'] = 15\n        n = distance.shape[0]\n        \n        fig = plt.figure(figsize = (10, 6))\n        ax = fig.add_subplot(1, 1, 1)\n        radius = np.ones((n, 1))*svdd.model[\"radius\"]\n        ax.plot(radius, \n                color ='r',\n                linestyle = '-', \n                marker = 'None',\n                linewidth = 2,\n                markeredgecolor ='k',\n                markerfacecolor = 'w', \n                markersize = 6)\n        \n        ax.plot(distance,\n                color = 'k',\n                linestyle = ':',\n                marker='o',\n                linewidth=1,\n                markeredgecolor = 'k',\n                markerfacecolor = 'C4',\n                markersize = 6)\n        \n        ax.set_xlabel('Samples')\n        ax.set_ylabel('Distance')\n        \n        ax.legend([\"Radius\",\"Distance\"], \n                  ncol = 1, loc = 0, \n                  edgecolor = 'black', \n                  markerscale = 2, fancybox = True)\n    \n        plt.show() \n        \n    def testROC(label, distance):\n        \"\"\" \n        DESCRIPTION\n        \n        Plot the test ROC\n        \n        testROC(label, distance)\n        \n        --------------------------------------------------------------- \n        \n        INPUT\n        label            test label\n        distance         distance from test data to SVDD hypersphere \n        \n        --------------------------------------------------------------- \n    \n        \"\"\"\n        if np.abs(np.sum(label)) == label.shape[0]:\n            raise SyntaxError('Both positive and negative labels must be entered for plotting ROC curve.')\n            \n        # number of positive samples\n        plt.rcParams['font.size'] = 15\n        n_p = np.sum(label == 1)\n        n_n = np.sum(label == -1)\n        \n        #sort\n        index = np.argsort(distance)\n        label_sort = label[index]\n        FP = np.cumsum(label_sort == -1)\n        TP = np.cumsum(label_sort == 1)\n        FPR = FP/n_n\n        TPR = TP/n_p\n        \n        roc_auc = auc(FPR.T, TPR.T) \n                  \n        fig = plt.figure(figsize = (6, 6))\n        ax = fig.add_subplot(1, 1, 1)\n        ax.plot(FPR.T, TPR.T,\n                color ='C3',\n                linestyle = '-', \n                marker = 'None',\n                linewidth = 5, \n                markeredgecolor ='k',\n                markerfacecolor = 'w', \n                markersize = 6)\n        \n        ax.set_xlabel('False positive rate (FPR)')\n        ax.set_ylabel('True positive rate (TPR)')\n        ax.set_title('Area under the curve (AUC) = %.4f' %roc_auc)\n        \n        plt.grid()\n        plt.show()\n        \n        \n    def boundary(svdd, data, label, r=0.3, nn=2):\n        \"\"\" \n        DESCRIPTION\n        \n        Plot the boundary\n        \n        boundary(svdd, data, label, r=0.3, nn=2)\n        \n        --------------------------------------------------------------- \n        \n        INPUT\n        svdd             SVDD hypersphere\n        data             training data \n        label            training label\n        r                radio of expansion (0<r<1)\n        nn               number of grids\n        \n        --------------------------------------------------------------- \n        \n        \"\"\" \n        \n        dim = data.shape[1]\n        if dim!=2:\n            raise SyntaxError('Visualization of decision boundary only supports for 2D data')\n    \n        # compute the range of grid \n        numGrids = np.rint(data.shape[0]/nn).astype(int)  # number of grids\n        x_range = np.zeros(shape=(numGrids, 2))\n        for i in range(2):  \n            _tmp_ = (np.max(data[:, i])-np.min(data[:, i]))*r\n            xlim_1 = np.min(data[:, i])-_tmp_\n            xlim_2 = np.max(data[:, i])+_tmp_\n            x_range[:, i] = np.linspace(xlim_1, xlim_2, numGrids)\n        \n        # grid\n        xv, yv = np.meshgrid(x_range[:, 0], x_range[:, 1])\n        \n        num1 = xv.shape[0]\n        num2 = yv.shape[0]\n        distance = np.zeros(shape=(num1, num1))\n        \n        # calculate the grid scores\n        print(\"Calculating the grid (%04d*%04d) scores...\\n\" %(num1, num2))\n        \n        display_ = svdd.parameters[\"option\"][\"display\"]\n        svdd.parameters[\"option\"][\"display\"] = 'off'\n        start_time = time.time()       \n        for i in range(num1):\n            for j in range(num2):\n                tmp = np.mat([xv[i, j], yv[i, j]])   \n                distance[i, j], _ = svdd.test(tmp, 1)\n                # print('[feature 1: %06d]  [feature 2: %06d] \\n' % (i+1,j+1))\n        end_time = time.time()\n        print('Grid scores completed. Time cost %.4f s\\n' % (end_time-start_time))\n        svdd.parameters[\"option\"][\"display\"] = display_\n        \n        \"\"\"\n        # plot the contour (3D)\n        fig = plt.figure(figsize = (20, 6))\n        \n        ax3 = fig.add_subplot(1, 3, 1, projection='3d') \n        # ax3 = ax3.axes(projection='3d')\n        ada = ax3.plot_surface(xv, yv, distance, cmap=plt.cm.jet)\n        ax3.contourf(xv, yv, distance, zdir='z', offset=np.min(distance)*0.9, cmap=plt.cm.coolwarm)\n        ax3.set_zlim(np.min(distance)*0.9, np.max(distance)*1.05)\n        # plt.colorbar(ada)\n            \n\n        # plot the contour (2D)\n        # fig = plt.figure(figsize = (10, 8))\n        ax1 = fig.add_subplot(1, 3, 2)    \n          \n        ctf1 = ax1.contourf(xv, yv, distance, alpha = 0.8, cmap=plt.cm.jet)\n        ctf2 = ax1.contour(xv, yv, distance, colors='black', linewidths=1)\n        plt.clabel(ctf2, inline=True)\n        # plt.colorbar(ctf1)\n        \n        \"\"\"\n        \n        # plot the boundary\n        fig = plt.figure(figsize = (15, 15))\n        ax2 = fig.add_subplot(1, 1, 1)    \n        \n        if svdd.labeltype == 'single':\n\n            ax2.scatter(data[:,0], data[:,1],\n                        color='yellow',marker='o',\n                        edgecolor='black',alpha=0.5, zorder = 2)\n            ax2.scatter(data[svdd.model[\"sv_index\"],0], data[svdd.model[\"sv_index\"],1],\n                    facecolor='C2',marker='o',s = 144,linewidths = 2,\n                    edgecolor='black', zorder = 2)\n        \n            ax2.contour(xv, yv, distance,[svdd.model[\"radius\"]],\n                              colors='C3', linewidths=5, zorder = 1)\n            \n            ax2.legend([\"Training data\", \"Support vectors\"], \n                      ncol = 1, loc = 0, \n                      edgecolor = 'black',markerscale = 1.2, fancybox = True) \n                \n        else:\n            ax2.scatter(data[svdd.model[\"pIndex\"],0], data[svdd.model[\"pIndex\"],1],\n                    facecolor='C0',marker='o', s = 100,linewidths = 2,\n                    edgecolor='black', zorder = 2)\n            ax2.scatter(data[svdd.model[\"nIndex\"],0], data[svdd.model[\"nIndex\"],1],\n                    facecolor='C4',marker='s',s = 100,linewidths = 2,\n                    edgecolor='black', zorder = 2)\n        \n            ax2.scatter(data[svdd.model[\"sv_index\"],0], data[svdd.model[\"sv_index\"],1],\n                    facecolor='C2',marker='o',s = 144,linewidths = 2,\n                    edgecolor='black', zorder = 2)\n            \n            ax2.contour(xv, yv, distance,[svdd.model[\"radius\"]],\n                              colors='C3', linewidths=5, zorder = 1)\n            \n            ax2.legend([\"Training data (+)\",\"Training data (-)\", \"Support vectors\"], \n                      ncol = 1, loc = 0, \n                      edgecolor = 'black',markerscale = 1.2, fancybox = True) \n        \n        plt.show()\n        ","metadata":{"execution":{"iopub.execute_input":"2021-01-30T23:25:02.048485Z","iopub.status.busy":"2021-01-30T23:25:02.043179Z","iopub.status.idle":"2021-01-30T23:25:02.088822Z","shell.execute_reply":"2021-01-30T23:25:02.088192Z"},"papermill":{"duration":12.57907,"end_time":"2021-01-30T23:25:02.088931","exception":false,"start_time":"2021-01-30T23:24:49.509861","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# APPLICATION OF SVDD","metadata":{"papermill":{"duration":12.670959,"end_time":"2021-01-30T23:25:27.453483","exception":false,"start_time":"2021-01-30T23:25:14.782524","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Change index value of y_test and y_train to : 0 == 1 and 1 == -1\nY_test1= Y_test.values\nY_test_list= []\nfor i in range(len(Y_test)):\n    if Y_test[i]==0:\n        Y_test[i]=1\n    else:\n        Y_test[i]=-1\n    y1=[]\n    y1.append(Y_test[i])\n    y1=np.array(y1)\n    Y_test_list.append(y1) \ny_test = np.array(Y_test_list)\n\nY_train1= Y_train.values\nY_train_list= []\nfor y in Y_train1:\n    if y==0:      \n        y1=[]\n        y1.append(1)\n        y1=np.array(y1)\n        Y_train_list.append(y1)\ny_train = np.array(Y_train_list)","metadata":{"execution":{"iopub.execute_input":"2021-01-30T23:25:53.131837Z","iopub.status.busy":"2021-01-30T23:25:53.131232Z","iopub.status.idle":"2021-01-30T23:25:55.31445Z","shell.execute_reply":"2021-01-30T23:25:55.313822Z"},"papermill":{"duration":14.695738,"end_time":"2021-01-30T23:25:55.314575","exception":false,"start_time":"2021-01-30T23:25:40.618837","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nker = {\"type\": 'gauss', \"width\": s}\n        ker = {\"type\": 'linear', \"offset\": c}\n        ker = {\"type\": 'ploy', \"degree\": d, \"offset\": c}\n        ker = {\"type\": 'tanh', \"gamma\": g, \"offset\": c}\n        ker = {\"type\": 'lapl', \"width\": s}\n\"\"\"\nnu= Fraud.shape[0]/Normal.shape[0]\n# set SVDD parameters\nparameters = {\"positive penalty\": 0.9,\n              \"negative penalty\": [],\n              \"kernel\": {\"type\": 'gauss', \"width\": 1/24},\n              \"option\": {\"display\": 'on'}}","metadata":{"execution":{"iopub.execute_input":"2021-01-30T23:26:20.623163Z","iopub.status.busy":"2021-01-30T23:26:20.622504Z","iopub.status.idle":"2021-01-30T23:26:20.625227Z","shell.execute_reply":"2021-01-30T23:26:20.624644Z"},"papermill":{"duration":12.765181,"end_time":"2021-01-30T23:26:20.625349","exception":false,"start_time":"2021-01-30T23:26:07.860168","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train SVDD model\nstart = 0\nend = 8000\nmodels = []\nfor i in range(20):\n    svdd = SVDD(parameters)\n    svdd.train(r_xtrain[start:end], y_train[start:end]) # 0-8000\n    models.append(svdd)\n    start = end\n    end += 8000 ","metadata":{"execution":{"iopub.execute_input":"2021-01-30T23:26:45.690727Z","iopub.status.busy":"2021-01-30T23:26:45.689596Z","iopub.status.idle":"2021-01-31T01:42:01.279643Z","shell.execute_reply":"2021-01-31T01:42:01.280657Z"},"papermill":{"duration":8128.018265,"end_time":"2021-01-31T01:42:01.280968","exception":false,"start_time":"2021-01-30T23:26:33.262703","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test SVDD model\nresults = []\nst = 0\nsd = 3000\nfor i in models:\n    accuracy = []\n    for j in range(2):\n        distance, acc= i.test(r_xtest[st:sd], y_test[st:sd])\n        accuracy.append(np.array(acc))\n    accuracy = np.array(accuracy)\n    results.append(np.mean(accuracy,axis=0))\ndf = pd.DataFrame(results,columns=[\"accuracy\",\"recall\",\"f1\",\"precision\"])\ndf.to_csv(\"results.csv\",index=False)","metadata":{"execution":{"iopub.execute_input":"2021-01-31T01:42:27.333305Z","iopub.status.busy":"2021-01-31T01:42:27.332623Z","iopub.status.idle":"2021-01-31T01:43:06.039779Z","shell.execute_reply":"2021-01-31T01:43:06.039178Z"},"papermill":{"duration":51.641787,"end_time":"2021-01-31T01:43:06.039902","exception":false,"start_time":"2021-01-31T01:42:14.398115","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# visualize test results\nVisualization.testResult(svdd, distance)","metadata":{"execution":{"iopub.execute_input":"2021-01-31T01:43:31.546301Z","iopub.status.busy":"2021-01-31T01:43:31.545211Z","iopub.status.idle":"2021-01-31T01:43:31.777593Z","shell.execute_reply":"2021-01-31T01:43:31.778126Z"},"papermill":{"duration":13.017651,"end_time":"2021-01-31T01:43:31.778268","exception":false,"start_time":"2021-01-31T01:43:18.760617","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# COUBRE ROC\nVisualization.testROC(y_test[st:sd], distance)","metadata":{"execution":{"iopub.execute_input":"2021-01-31T01:43:57.340965Z","iopub.status.busy":"2021-01-31T01:43:57.340317Z","iopub.status.idle":"2021-01-31T01:43:57.498374Z","shell.execute_reply":"2021-01-31T01:43:57.49782Z"},"papermill":{"duration":12.859921,"end_time":"2021-01-31T01:43:57.498482","exception":false,"start_time":"2021-01-31T01:43:44.638561","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}